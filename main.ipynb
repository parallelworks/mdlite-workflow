{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Dynamics Lite workflow\n",
    "This notebook implements a simple molecular dynamics workflow to demonstrate [Parsl Python parallel scripting](https://parsl-project.org/) in a Jupyter notebook.\n",
    "\n",
    "## Step 1: Define workflow inputs\n",
    "This PW workflow can be either launched from its form in the `Compute` tab or it can be run directly in this notebook.  If running directly from the notebook, the user needs to go through the extra step of defining the inputs of the workfow in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "print('Define workflow inputs...')\n",
    "\n",
    "# Start assuming workflow is launched from the form.\n",
    "run_in_notebook=False\n",
    "\n",
    "if (exists(\"./params.run\")):\n",
    "    print(\"Running from a PW form.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Running from a notebook.\")\n",
    "    \n",
    "    # Set flag for later\n",
    "    run_in_notebook=True\n",
    "    \n",
    "    #TO DO: AUTOMATE THE PROCESS OF GRABING PW.CONF.\n",
    "    \n",
    "    # Manually set workflow inputs here\n",
    "    params=\"npart;input;25:100:25|steps;input;3000:9000:3000|mass;input;0.01|trsnaps;input;10|\"\n",
    "    \n",
    "    print(params)\n",
    "    \n",
    "    # Write to params.run\n",
    "    with open(\"params.run\",\"w\") as f:\n",
    "        n_char_written = f.write(params+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Parsl\n",
    "The molecular dynamics software itself is a lightweight, precompiled executable written in C. The executable is distributed with this workflow in `./models/mdlite`, and along with input files, it is staged to the remote resources and does not need to be preinstalled.\n",
    "\n",
    "The core visualization tool used here is a precompiled binary of [c-ray](https://github.com/vkoskiv/c-ray) distributed with this workflow in `./models/c-ray`. The executable is staged to remote resources and does not need to be preinstalled.\n",
    "\n",
    "In addition to a Miniconda environment containing Parsl, the only other dependency of this workflow is ImageMagick's `convert` tool for image format conversion (`.ppm` to `.png`) and building animated `.gif` files from `.png` frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configuring Parsl...\")\n",
    "#from glob import glob\n",
    "\n",
    "import parsl\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.data_provider.files import File\n",
    "from path import Path\n",
    "from parslpw import pwconfig,pwargs\n",
    "\n",
    "if (not run_in_notebook):\n",
    "    print(pwargs)\n",
    "\n",
    "parsl.load(pwconfig)\n",
    "print(\"pwconfig loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Parsl workflow apps\n",
    "These apps are decorated with Parsl's `@bash_app` and as such are executed in parallel on the compute resources that are defined in the PW configuration loaded above.  Functions that are **not** decorated are not executed in parallel on remote resources. The files that need to be staged to remote resources will be marked with Parsl's `File()` (or its PW extension, `Path()`) in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Defining Parsl workflow apps...\")\n",
    "\n",
    "@bash_app\n",
    "def run_md(stdout='md.app.stdout', stderr='md.app.stderr', inputs=[], outputs=[]):\n",
    "    return '''\n",
    "    %s/runMD.sh \"%s\" trjOut mexOut\n",
    "    outdir=%s\n",
    "    mkdir -p $outdir\n",
    "    mv trjOut $outdir/\n",
    "    mv mexOut $outdir/\n",
    "    ''' % (inputs[1],inputs[0],outputs[0])\n",
    "    \n",
    "#    import os\n",
    "#    label = os.path.splitext(os.path.basename(outputs[0]))[0]\n",
    "#    run_script = os.path.basename(inputs[0])\n",
    "#    docker = os.path.basename(inputs[2])\n",
    "#\n",
    "#    sed_command = \"sed -i -e 's,_XYZFILE_,%s.xyz,' -e 's/_NAME_/%s/' %s\"%(os.path.splitext(os.path.basename(inputs[1]))[0],label,os.path.basename(inputs[0]))\n",
    "#    nwchem_command = \"/bin/bash \" + docker + \" \" + run_script + \" > \" + os.path.basename(outputs[0])\n",
    "#    \n",
    "#    return '''\n",
    "#        %s \n",
    "#        %s\n",
    "#        mkdir -p outputs/out\n",
    "#        mkdir -p outputs/db\n",
    "#        mv *.db outputs/db\n",
    "#        mv *.out outputs/out\n",
    "#    ''' % (sed_command,nwchem_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Workflow\n",
    "This cell executes the workflow itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running workflow...\")\n",
    "\n",
    "# Generate a case list from params.run (the ranges to parameters to sweep)\n",
    "os.system(\"python ./models/mexdex/prepinputs.py params.run cases.list\")\n",
    "\n",
    "# Each line in cases.list is a unique combination of the parameters to sweep.\n",
    "with open(\"cases.list\",\"r\") as f:\n",
    "    cases_list = f.readlines()\n",
    "\n",
    "# For each line in cases.list, run and visualize a molecular dynamics simulation\n",
    "for ii, case in enumerate(cases_list):\n",
    "    print(case)\n",
    "    r = run_md(\n",
    "        inputs=[case,\n",
    "            Path(\"./models/mdlite\")],\n",
    "        outputs=[Path(\"./results/case_\"+str(ii))])\n",
    "    r.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Clean up\n",
    "This step is only necessary when running directly in a notebook. These intermediate and log files are removed to keep the workflow file structure clean if this workflow is pushed into the PW Market Place.  Please feel free to comment out these lines in order to inspect intermediate files as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_in_notebook):\n",
    "    !rm -f params.run\n",
    "    !rm -rf runinfo\n",
    "    !rm -rf __pycache__\n",
    "    !rm -f cases.list\n",
    "    !rm -rf parsl-task.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
