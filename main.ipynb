{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Dynamics Lite workflow\n",
    "This notebook implements a simple molecular dynamics (MD) workflow to demonstrate [Parsl Python parallel scripting](https://parsl-project.org/) in a Jupyter notebook. This workflow first runs MD simulations in parallel on remote resources and then renders the frames of an animation visualizing the simulation according to the schematic below.\n",
    "\n",
    "The molecular dynamics software itself is a lightweight, precompiled executable written in C. The executable is distributed with this workflow in `./models/mdlite`, and along with input files, it is staged to the remote resources and does not need to be preinstalled.\n",
    "\n",
    "The core visualization tool used here is a precompiled binary of [c-ray](https://github.com/vkoskiv/c-ray) distributed with this workflow in `./models/c-ray`. The executable is staged to remote resources and does not need to be preinstalled.\n",
    "\n",
    "In addition to a Miniconda environment containing Parsl, the only other dependency of this workflow is ImageMagick's `convert` tool for image format conversion (`.ppm` to `.png`) and building animated `.gif` files from `.png` frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For displaying schematic and embedding Design Explorer results in notebook\n",
    "from IPython.display import Image, IFrame\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "def PWFrame(url,height=600):\n",
    "    return IFrame(url, width=800, height=height)\n",
    "\n",
    "Image(\"images/mdlite-parameter-sweep.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Define workflow inputs\n",
    "This PW workflow is always launched from its form in the `Compute` tab. Subsequent execution can be controlled either through this notebook (i.e. interactive) or it can be run directly via its corresponding `main.py`.  If running directly from the notebook, the user needs to check `Yes` for the `Run in notebook?` toggle switch at the top of the launch form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get working directory from underlying shell\n",
    "pwd=!pwd\n",
    "print('Running in: '+pwd[0])\n",
    "    \n",
    "if (exists(\"./params.run\") ):\n",
    "    # You have already launched the workflow and have likely opened\n",
    "    # this notebook in /pw/jobs/mdlite/<job_number>/main.ipynb.\n",
    "    # There is no need launch the workflow again, so the form is not \n",
    "    # displayed.\n",
    "    print('Workflow already launched, parsl_utils set up is complete.')\n",
    "else:\n",
    "    # The workflow needs to be launched.\n",
    "    print('Please launch the workflow from the Workflows tab and select `Yes` for `Run in notebook`.')\n",
    "    print('Then, please open the Jupyter notebook in /pw/jobs/<workflow_name>/<job_number>.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsl essentials\n",
    "import parsl\n",
    "from parsl.app.app import python_app, bash_app\n",
    "print(parsl.__version__, flush = True)\n",
    "\n",
    "# PW essentials, includes resource and workflow parameters\n",
    "import parsl_utils\n",
    "from parsl_utils.config import config, resource_labels, form_inputs\n",
    "from parsl_utils.data_provider import PWFile\n",
    "\n",
    "# For making a plot of the results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Workflow parameters have already been converted to params.run\n",
    "# in main.py and parsl_utils setup has already run. This notebook\n",
    "# can proceed immdiately to loading Parsl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Configure Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configuring Parsl...\")\n",
    "parsl.load(config)\n",
    "print(\"Parsl config loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define Parsl workflow apps\n",
    "These apps are decorated with Parsl's `@bash_app` and as such are executed in parallel on the compute resources that are defined in the PW configuration loaded above.  Functions that are **not** decorated are not executed in parallel on remote resources. The files that need to be staged to remote resources will be marked with Parsl's `File()` (or its PW extension, `PWFile()`) in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Defining Parsl workflow apps...\")\n",
    "\n",
    "#===================================\n",
    "# Molecular dynamics simulation app\n",
    "#===================================\n",
    "\n",
    "# Sleeps inserted to allow time for\n",
    "# concurrent rsyncs from all invocations\n",
    "# of this app to finish transfering srcdir.\n",
    "\n",
    "# The log_app decorator is OPTIONAL and\n",
    "# prints out all the inputs and outputs.\n",
    "@parsl_utils.parsl_wrappers.log_app\n",
    "@bash_app(executors=[resource_labels[0]])\n",
    "def md_run(case_definition, inputs=[], outputs=[], stdout='md.run.stdout', stderr='md.run.stderr'):\n",
    "    return '''\n",
    "    sleep 10\n",
    "    mkdir -p {outdir}\n",
    "    cd {outdir}\n",
    "    {srcdir}/mdlite/runMD.sh \"{runopt}\" metric.out trj.out\n",
    "    '''.format(\n",
    "        runopt = case_definition,\n",
    "        srcdir = inputs[0].local_path,\n",
    "        outdir = outputs[0].local_path\n",
    "    )\n",
    "\n",
    "#===================================\n",
    "# App to render frames for animation\n",
    "#===================================\n",
    "# All frames for a given simulation\n",
    "# are rendered together.\n",
    "\n",
    "# This app takes a very simple \n",
    "# approach to zero padding by adding \n",
    "# integers to 1000.\n",
    "@parsl_utils.parsl_wrappers.log_app\n",
    "@bash_app(executors=[resource_labels[1]])\n",
    "def md_vis(num_frames, inputs=[], outputs=[], stdout='md.vis.stdout', stderr='md.vis.stderr'):\n",
    "    return '''\n",
    "    sleep 10\n",
    "    mkdir -p {outdir}\n",
    "    for (( ff=0; ff<{nf}; ff++ ))\n",
    "    do\n",
    "        frame_num_padded=$((1000+$ff))\n",
    "        {srcdir}/c-ray/renderframe_shared_fs {indir}/md/trj.out {outdir}/f_$frame_num_padded.ppm $ff\n",
    "    done\n",
    "    '''.format(\n",
    "        nf = num_frames,\n",
    "        srcdir = inputs[0].local_path,\n",
    "        indir = inputs[1].local_path,\n",
    "        outdir = outputs[0].local_path\n",
    "    )\n",
    "\n",
    "print(\"Done defining Parsl workflow apps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Workflow\n",
    "\n",
    "## Simulation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running workflow...\")\n",
    "\n",
    "#============================================================================\n",
    "# SETUP PARAMETER SWEEP\n",
    "#============================================================================\n",
    "# Generate a case list from params.run (the ranges to parameters to sweep)\n",
    "# It is possible to manually change the params.run and rerun this cell to\n",
    "# change the input parameters to the simulation.\n",
    "os.system(\"python ./models/mexdex/prepinputs.py params.run cases.list\")\n",
    "\n",
    "# Each line in cases.list is a unique combination of the parameters to sweep.\n",
    "with open(\"cases.list\",\"r\") as f:\n",
    "    cases_list = f.readlines()\n",
    "\n",
    "#============================================================================\n",
    "# SIMULATE\n",
    "#============================================================================\n",
    "# For each line in cases.list, run and visualize a molecular dynamics simulation\n",
    "# The empty list will store the futures of Parsl-parallelized apps. Set the local\n",
    "# and remote working directories for this app here.\n",
    "md_run_fut = []\n",
    "local_dir = os.getcwd()\n",
    "remote_dir = config.executors[0].working_dir+\"/sim\"\n",
    "\n",
    "for ii, case in enumerate(cases_list):\n",
    "    # Define remote working (sub)dir for this case\n",
    "    case_dir = \"case_\"+str(ii)\n",
    "    \n",
    "    # Run simulation\n",
    "    md_run_fut.append(\n",
    "        md_run(\n",
    "            case_definition = case,\n",
    "            inputs = [\n",
    "                PWFile(\n",
    "                    # Rsync with \"copy dir by name\" no trailing slash convention\n",
    "                    url = 'file://usercontainer/'+local_dir+'/models/mdlite',\n",
    "                    local_path = remote_dir+'/src'\n",
    "                )\n",
    "            ],\n",
    "            outputs = [\n",
    "                PWFile(\n",
    "                    url = 'file://usercontainer/'+local_dir+'/results/'+case_dir,\n",
    "                    local_path = remote_dir+'/'+case_dir+'/md'\n",
    "                )\n",
    "            ],\n",
    "            # Any files in outputs directory at end of app are rsynced back\n",
    "            stdout = remote_dir+'/'+case_dir+'/md/std.out',\n",
    "            stderr = remote_dir+'/'+case_dir+'/md/std.err'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force workflow to wait for all simulation apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call results for all app futures to require\n",
    "# execution to wait for all simulations to complete.\n",
    "for run in md_run_fut:\n",
    "    run.result()\n",
    "    \n",
    "print('Done with simulations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# VISUALIZE\n",
    "#============================================================================\n",
    "md_vis_fut = []\n",
    "local_dir = os.getcwd()\n",
    "remote_dir = config.executors[1].working_dir+\"/vis\"\n",
    "\n",
    "for ii, case in enumerate(cases_list):\n",
    "    # Define remote working dir for this case\n",
    "    case_dir = \"case_\"+str(ii)\n",
    "        \n",
    "    # Get number of frames to render for this case\n",
    "    nframe = int(case.split(',')[4])\n",
    "    \n",
    "    #=========================================================\n",
    "    # Render all frames for each case in one app.  This approach\n",
    "    # reduces the number of SSH connections (e.g. rsync instances) \n",
    "    # compared to an app that only renders one frame at a time.\n",
    "    md_vis_fut.append(\n",
    "        md_vis(\n",
    "            nframe,\n",
    "            inputs=[\n",
    "                PWFile(\n",
    "                    url = 'file://usercontainer/'+local_dir+'/models/c-ray',\n",
    "                    local_path = remote_dir+'/src'\n",
    "                ),\n",
    "                PWFile(\n",
    "                    url = 'file://usercontainer/'+local_dir+'/results/'+case_dir+'/md',\n",
    "                    local_path = remote_dir+'/'+case_dir\n",
    "                )\n",
    "            ],\n",
    "            outputs=[\n",
    "                PWFile(\n",
    "                    url = 'file://usercontainer/'+local_dir+'/results/'+case_dir,\n",
    "                    local_path = remote_dir+'/'+case_dir+'/vis'\n",
    "                )\n",
    "            ],\n",
    "            stdout = remote_dir+'/'+case_dir+'/vis/std.out',\n",
    "            stderr = remote_dir+'/'+case_dir+'/vis/std.err'\n",
    "        )\n",
    "    )\n",
    "\n",
    "for vis in md_vis_fut:\n",
    "    vis.result()\n",
    "    \n",
    "# Compile frames into movies locally\n",
    "for ii, case in enumerate(cases_list):\n",
    "    os.system(\"cd ./results/case_\"+str(ii)+\"/vis; convert -delay 10 *.ppm mdlite.gif\")\n",
    "\n",
    "# Compile movies into Design Explorer results locally\n",
    "os.system(\"./models/mexdex/postprocess.sh mdlite_dex.csv mdlite_dex.html ./\")\n",
    "\n",
    "print('Done with visualizations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: View results in Design Explorer\n",
    "This step is only necessary when running directly in a notebook. The outputs of this workflow are stored in the `results` folder and they can be interactively visualized with the Design Explorer by clicking on `mdlite_dex.html` which uses `mdlite_dex.csv` and the data in the `results` folder. The Design Explorer visualization is automatically embedded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure path to datafile=/pw/workflows/mdlite/mdlite_dex.csv is correct\n",
    "nb_cwd = os.getcwd()\n",
    "PWFrame(\n",
    "    '/DesignExplorer/index.html?datafile='+nb_cwd+'/mdlite_dex.csv&colorby=kinetic',\n",
    "    height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Use notebook to interact directly with simulation results\n",
    "Jupyter notebooks are great because cells can be re-run in isolation as ideas are fine-tuned.  The cell below allows for plotting a new result directly from the simulation outputs; there is no need to re-run the simulation if the plot needs to be modified as the user explores the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data are in the results/case_* folders.\n",
    "list_of_cases = glob.glob(\"results/case_*\")\n",
    "\n",
    "# Initialize lists to store data for plotting\n",
    "cases = []\n",
    "all_cases_time_val = []\n",
    "all_cases_rt_mean_sq_std = []\n",
    "all_cases_rt_mean_sq_mean = []\n",
    "\n",
    "# Loop through each case\n",
    "for case in list_of_cases:\n",
    "\n",
    "    # Get info about this case\n",
    "    path = case + \"/md/trj.out\"\n",
    "    case_name = case[case.index('case'):]\n",
    "    cases.append(case_name)\n",
    "    \n",
    "    # Load data for this case\n",
    "    data = pd.read_csv(path, sep=\" \")\n",
    "    data.columns=['time', 'var', 'x_pos', 'y_pos', 'z_pos', 'ig0', 'ig1', 'ig2', 'ig3', 'ig4', 'ig5']\n",
    "    t_val = data['time'].unique()\n",
    "    all_cases_time_val.append(t_val)\n",
    "    \n",
    "    # Create and initialize lists of root mean square for std and mean\n",
    "    one_case_rt_mean_sq_std = []\n",
    "    one_case_rt_mean_sq_mean = []\n",
    "\n",
    "    # Loop through each instance in time and compute statistics\n",
    "    for t in t_val:\n",
    "\n",
    "        each_time = data.loc[data['time'] == t, 'x_pos':'z_pos']\n",
    "        all_pos_std = each_time.std()\n",
    "        all_pos_mean = each_time.mean()\n",
    "        \n",
    "        # Calculate root mean square of std and mean (vector magnitude)\n",
    "        # Fix decimal points to 6\n",
    "        rt_mean_sq_std = math.sqrt((all_pos_std['x_pos'])**2 + (all_pos_std['y_pos'])**2 + (all_pos_std['z_pos'])**2)\n",
    "        one_case_rt_mean_sq_std.append(round(rt_mean_sq_std,6))\n",
    "        rt_mean_sq_mean = math.sqrt((all_pos_mean['x_pos'])**2 + (all_pos_mean['y_pos'])**2 + (all_pos_mean['z_pos'])**2)\n",
    "        one_case_rt_mean_sq_mean.append(round(rt_mean_sq_mean,6))\n",
    "        \n",
    "    # After getting all root mean square for std and mean of all time,\n",
    "    # put it in the list for all cases.\n",
    "    all_cases_rt_mean_sq_std.append(one_case_rt_mean_sq_std)\n",
    "    all_cases_rt_mean_sq_mean.append(one_case_rt_mean_sq_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot side by side root mean square std vs. time \n",
    "# and root mean square mean vs. time\n",
    "fig, (ax0, ax1) = plt.subplots(1,2,figsize=(20,5))\n",
    "\n",
    "# Go through each cases to plot\n",
    "# If desired to see some case not all,\n",
    "# could change range(len(cases)) to range(<some number less than len(cases)>)\n",
    "for c in range(len(cases)):\n",
    "    # Plot root mean square std vs. time with solid line\n",
    "    # and dots for each value (x,y) on the graph\n",
    "    # x-axis is time, y-axis is root mean square std\n",
    "    ax0.plot(all_cases_time_val[c],all_cases_rt_mean_sq_std[c],'-o')\n",
    "    ax0.set_xlabel('Time(s)', fontsize=20)\n",
    "    ax0.set_ylabel('RMS variance of positions', fontsize=15)\n",
    "\n",
    "    # Plot root mean square mean vs. time with solid line\n",
    "    # and squares for each value (x,y) on the graph\n",
    "    # x-axis is time, y-axis is root mean square mean\n",
    "    ax1.plot(all_cases_time_val[c],all_cases_rt_mean_sq_mean[c],'-s')\n",
    "    ax1.set_xlabel('Time(s)', fontsize=20)\n",
    "    ax1.set_ylabel('Magnitude of centroid position', fontsize=15)\n",
    "    \n",
    "# Add legend to show name of each case\n",
    "ax0.legend(cases)\n",
    "ax1.legend(cases)\n",
    "\n",
    "# Add title for each plot\n",
    "ax0.set_title(\"Spread of particle swarm\",\n",
    "              fontsize=25)\n",
    "ax1.set_title(\"Centroid of particle swarm\",\n",
    "              fontsize=25)\n",
    "\n",
    "plt.savefig('mdlite_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Iterative development clean up\n",
    "This step is only necessary when running directly in a notebook. These intermediate and log files are removed to keep the workflow file structure clean if this workflow is run several times during testing cycles.  **Note that even the results are deleted!** (Commented out for now in case users choose `Kernel -> Restart & Run All`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete outputs\n",
    "#!rm -rf ./results\n",
    "#!rm -f mdlite_*.*\n",
    "#!rm -f cases.list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Final workflow shutdown\n",
    "This step is only necessary when running directly in a notebook. The `main.py` script launched by `parsl_utils` is waiting for this flag to clean up the resources and shut down the tunnels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_message = \"Executed final workflow shutdown from Jupyter notebook.\"\n",
    "with open(\"notebook_done.flag\",\"w\") as f:\n",
    "    n_char_written = f.write(done_message+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
